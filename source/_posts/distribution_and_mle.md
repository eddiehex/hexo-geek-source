---
title: 各类分布及其MLE推导
date: 2025-04-20
categories:
  - Statistics
tags: [Statistics, MLE]
toc: true
excerpt: "统计分布和MLE的构建"
---

**核心概念：为什么需要概率分布？**

想象一下你想描述一个随机现象的结果，比如：

*   抛一次硬币的结果（正面还是反面？）
*   明天会不会下雨（是还是否？）
*   一个班级学生的身高（具体数值是多少？）
*   一小时内某个路口通过的汽车数量（具体数量是多少？）

概率分布就是用来**数学化地描述这些随机现象（随机变量）可能出现的结果以及每个结果出现的可能性（概率或概率密度）**的工具。它就像一个“蓝图”或“配方”，告诉我们数据大概长什么样。

**关键组成部分：**

*   **随机变量 (Random Variable):** 一个变量，它的值是某个随机过程的结果。通常用大写字母表示，如 X、Y。
    *   **离散随机变量 (Discrete):** 只能取有限个或可数无限个特定值（如上面例子中的硬币结果、下雨与否、汽车数量）。
    *   **连续随机变量 (Continuous):** 可以取某个区间内的任意值（如上面例子中的身高）。
*   **参数 (Parameters):** 控制分布具体形状和位置的“旋钮”或“设定值”。它们通常是未知的，是我们需要通过数据（比如用 MLE）来估计的对象。用希腊字母表示很常见，如 p, λ, μ, σ。
*   **概率质量函数 (PMF) 或 概率密度函数 (PDF):**
    *   **PMF (Probability Mass Function):** 用于离散随机变量。它给出了随机变量取某个特定值的概率。通常写作 P(X=k)。所有可能值的概率加起来必须等于 1 (∑P(X=k)=1)。
    *   **PDF (Probability Density Function):** 用于连续随机变量。它本身的值不是概率，但它描述了数据在某个点附近的相对可能性（密度）。某个区间 [a,b] 内的概率是通过对 PDF 在该区间上积分得到的 $P(a \le X \le b) = \int_{a}^{b} f(x) dx$。整个定义域上的积分必须等于 1 ($\int_{-\infty}^{\infty} f(x) dx = 1$)。通常写作 f(x)。

这个 PMF 或 PDF 的数学表达式，就是我们用来计算“给定参数下，观测到某个数据的可能性”的基础，也是构建 MLE 中似然函数的关键！

**由浅入深看几种常见分布：**

**场景一：处理单个“是/否”或“成功/失败”事件 (离散)**

*   **分布：** 伯努利分布 (Bernoulli Distribution)
*   **描述：** 单次试验，只有两个可能结果（比如成功/失败，正面/反面，是/否），通常编码为 1 和 0。
*   **随机变量 X：** X=1 代表“成功”，X=0 代表“失败”。
*   **参数 θ=p：** p 是“成功” (X=1) 的概率 (0≤p≤1)。那么“失败” (X=0) 的概率就是 1−p。
*   **PMF 表达式 (P(X=k∣p)):** 这是一个巧妙的写法，能同时表达 X=1 和 X=0 的情况：

    $P(X=k | p) = p^k (1-p)^{1-k}$  其中 $k \in \{0, 1\}$

    验证一下：

    *   当 k=1 (成功)时， $P(X=1 | p) = p^1 (1-p)^{1-1} = p^1 (1-p)^0 = p$。
    *   当 k=0 (失败)时， $P(X=0 | p) = p^0 (1-p)^{1-0} = p^0 (1-p)^1 = 1-p$。
*   **Demo:** 抛掷一枚可能不均匀的硬币一次。假设我们猜测 p=0.7（正面概率是 0.7）。

    *   那么，观察到正面 (k=1) 的概率是 $P(X=1 | p=0.7) = 0.7$。
    *   观察到反面 (k=0) 的概率是 $P(X=0 | p=0.7) = 1 - 0.7 = 0.3$。
*   **MLE 应用：** 如果你观测到一次抛掷结果是 $x_1$ (比如 $x_1 = 1$)，那么这次观测的似然度 (Likelihood) 就是 $L(p | x_1) = P(X=x_1 | p) = p^{x_1} (1-p)^{1-x_1}$。如果有多次独立观测 $x_1, x_2, ..., x_n$，联合似然函数就是 $L(p) = \prod_{i=1}^{n} p^{x_i} (1-p)^{1-x_i}$。

**场景二：处理多次独立的“是/否”试验中，“成功”的总次数 (离散)**

*   **分布：** 二项分布 (Binomial Distribution)
*   **描述：** 进行 n 次独立的伯努利试验（每次试验成功的概率都是 p），计算总共“成功”了多少次。
*   **随机变量 X：** X 代表 n 次试验中成功的总次数。X 可以取 0, 1, 2, ..., n 这些整数值。
*   **参数 θ=(n,p)：** n 是总试验次数（通常是已知的），p 是单次试验成功的概率（通常是需要估计的）。
*   **PMF 表达式 (P(X=k∣n,p)):**

    $P(X=k | n, p) = \binom{n}{k} p^k (1-p)^{n-k}$  其中 $k = 0, 1, ..., n$

    $\binom{n}{k} = \frac{n!}{k!(n-k)!}$ 是组合数，表示从 n 次试验中选出 k 次成功有多少种组合方式。

    *   $p^k$ 是 k 次成功发生的概率。
    *   $(1-p)^{n-k}$ 是 n−k 次失败发生的概率。
*   **Demo:** 抛掷一枚硬币 10 次 (n=10)，假设 p=0.7。想知道恰好观察到 8 次正面 (k=8) 的概率是多少？

    $P(X=8 | n=10, p=0.7) = \binom{10}{8} (0.7)^8 (1-0.7)^{10-8} = 45 \times (0.7)^8 \times (0.3)^2 \approx 0.233$。
*   **MLE 应用：**
    *   情况 A (已知 n 次试验，观测到总成功数 k)： 如果你做了 n 次试验，观测到总共有 k 次成功，那么似然函数就是 $L(p | k, n) = \binom{n}{k} p^k (1-p)^{n-k}$。然后你寻找使这个 L(p) 最大的 p。
    *   情况 B (已知 n 次试验的每次结果)： 如果你知道每次试验的结果 $x_1, x_2, ..., x_n$（每个 $x_i$ 是 0 或 1），这其实回到了伯努利的情况。你使用 n 个伯努利观测的联合似然函数：$L(p) = \prod_{i=1}^{n} p^{x_i} (1-p)^{1-x_i}$。最终通过 MLE 估计出的 p 在这两种情况下是相同的，等于样本中成功的比例 $\frac{\sum x_i}{n}$ 或 $\frac{k}{n}$。

**场景三：处理单位时间/空间内发生某事件的次数 (离散)**

*   **分布：** 泊松分布 (Poisson Distribution)
*   **描述：** 计算在固定的时间段、区域、体积等内，某个稀有事件发生的次数。假设事件独立发生，且平均发生率恒定。
*   **随机变量 X：** X 代表在给定单位内事件发生的次数。X 可以取 0, 1, 2, ... 这些非负整数。
*   **参数 θ=λ (lambda):** λ 是单位时间/空间内事件发生的平均次数 (λ>0)。
*   **PMF 表达式 (P(X=k∣λ)):**

    $P(X=k | \lambda) = \frac{e^{-\lambda} \lambda^k}{k!}$  其中 $k = 0, 1, 2, ...$

    *   $e \approx 2.71828$ 是自然常数。
    *   $k!$ 是 k 的阶乘。
*   **Demo:** 某个呼叫中心平均每小时接到 5 个电话 (λ=5)。想知道在接下来的一小时内，恰好接到 3 个电话 (k=3) 的概率是多少？

    $P(X=3 | \lambda=5) = \frac{e^{-5} 5^3}{3!} = \frac{e^{-5} \times 125}{6} \approx 0.14$。
*   **MLE 应用：** 如果你观测了 n 个时间段，每个时间段内事件发生的次数分别是 $x_1, x_2, ..., x_n$。假设它们都服从参数为 λ 的泊松分布。

    *   单个观测 $x_i$ 的概率是 $P(X=x_i | \lambda) = \frac{e^{-\lambda} \lambda^{x_i}}{x_i!}$。
    *   联合似然函数是 $L(\lambda) = \prod_{i=1}^{n} \frac{e^{-\lambda} \lambda^{x_i}}{x_i!} = \frac{e^{-n\lambda} \lambda^{\sum x_i}}{\prod x_i!}$。
    *   通过最大化这个 L(λ)（或其对数），可以得到 λ 的 MLE 估计值，结果是样本均值 $\hat{\lambda}_{MLE} = \frac{1}{n} \sum_{i=1}^{n} x_i$。

**场景四：处理某个区间内均匀随机取值 (连续)**

*   **分布：** 均匀分布 (Uniform Distribution)
*   **描述：** 在一个指定的区间 [a,b] 内，随机变量取任何值的可能性都是相等的。区间外取值的概率为 0。
*   **随机变量 X：** 在 [a,b] 区间内取值。
*   **参数 θ=(a,b)：** a 是区间的下界，b 是区间的上界 (a<b)。
*   **PDF 表达式 (f(x∣a,b)):**

    $ f(x | a, b) = \begin{cases} \frac{1}{b-a} & \text{如果 } a \le x \le b \\ 0 & \text{其他情况} \end{cases} $

    注意 PDF 的值是 $\frac{1}{b-a}$ 这个常数，它不是概率，而是概率密度。整个区间的宽度是 b−a，高度是 $\frac{1}{b-a}$，所以总面积（总概率）是 $(b-a) \times \frac{1}{b-a} = 1$。
*   **Demo:** 计算机生成 [0,1] 之间的随机数 (a=0, b=1)。

    *   PDF 是 $f(x | 0, 1) = \frac{1}{1-0} = 1$，当 $0 \le x \le 1$ 时。
    *   取值在 [0.2, 0.3] 之间的概率是 $\int_{0.2}^{0.3} 1 dx = [x]_{0.2}^{0.3} = 0.3 - 0.2 = 0.1$。这正好是区间长度 (0.3−0.2) 乘以 PDF 的值 (1)。
*   **MLE 应用：** 如果你观测到数据 $x_1, ..., x_n$，假设它们来自 Uniform(a, b) 分布。

    *   似然函数 $L(a, b) = \prod_{i=1}^{n} f(x_i | a, b)$。仅当所有的 $x_i$ 都在 [a, b] 区间内时，似然函数才不为零，此时 $L(a, b) = (\frac{1}{b-a})^n$。
    *   为了最大化 L(a, b)，我们需要让区间 [a, b] 尽可能小（这样 $\frac{1}{b-a}$ 就尽可能大），但同时必须包含所有的观测数据 $x_i$。
    *   所以 a 的 MLE 是样本最小值 $\hat{a}_{MLE} = \min(x_i)$，b 的 MLE 是样本最大值 $\hat{b}_{MLE} = \max(x_i)$。

**场景五：处理事件发生前的等待时间 (连续)**

*   **分布：** 指数分布 (Exponential Distribution)
*   **描述：** 用于描述独立事件发生之间所需的时间，或者某个物品的使用寿命（如果损耗率恒定）。它是泊松过程的“姐妹”分布。
*   **随机变量 X：** 等待时间或寿命 (X≥0)。
*   **参数 θ=λ (lambda):** λ 是事件发生的速率 (rate parameter, λ>0)，即单位时间平均发生多少次事件。有时也用 β=1/λ (scale parameter) 作为参数。我们这里用速率参数 λ。
*   **PDF 表达式 (f(x∣λ)):**

    $ f(x | \lambda) = \begin{cases} \lambda e^{-\lambda x} & \text{如果 } x \ge 0 \\ 0 & \text{如果 } x < 0 \end{cases} $
*   **Demo:** 假设某个零件的平均寿命是 100 小时。那么失效率 λ=1/100=0.01 次/小时。

    *   该零件恰好在 50 小时 (x=50) 时刻的概率密度是 $f(50 | \lambda=0.01) = 0.01 e^{-0.01 \times 50} = 0.01 e^{-0.5} \approx 0.00607$。
    *   该零件寿命超过 50 小时的概率是 $P(X > 50) = \int_{50}^{\infty} 0.01 e^{-0.01x} dx = [-e^{-0.01x}]_{50}^{\infty} = 0 - (-e^{-0.5}) = e^{-0.5} \approx 0.607$。
*   **MLE 应用：** 观测到 n 个同类零件的寿命 $x_1, ..., x_n$，假设服从参数为 λ 的指数分布。

    *   似然函数 $L(\lambda) = \prod_{i=1}^{n} \lambda e^{-\lambda x_i} = \lambda^n e^{-\lambda \sum x_i}$ (假设所有 $x_i \ge 0$)。
    *   最大化对数似然函数 $\ell(\lambda) = n \ln \lambda - \lambda \sum x_i$。
    *   求导并令其为零 $\frac{d\ell}{d\lambda} = \frac{n}{\lambda} - \sum x_i = 0$。
    *   解得 λ 的 MLE 是 $\hat{\lambda}_{MLE} = \frac{n}{\sum x_i} = \frac{1}{\bar{x}}$，即样本均值的倒数。这很直观：平均寿命越长（$\bar{x}$ 大），失效率 λ 就越小。

**场景六：处理自然界中常见的测量误差、人群身高体重等 (连续)**

*   **分布：** 正态分布 (Normal Distribution) / 高斯分布 (Gaussian Distribution)
*   **描述：** 自然界和工程中极其常见的分布，形状像一个对称的钟。由中心位置和分散程度决定。
*   **随机变量 X：** 可以取任何实数值 (−∞, ∞)。
*   **参数 θ=(μ, σ²)：** μ (mu) 是分布的均值（决定钟形曲线的中心位置），σ² (sigma squared) 是方差（决定钟形曲线的胖瘦，σ²>0）。σ 是标准差。
*   **PDF 表达式 (f(x∣μ,σ²)):**

    $f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$

    *   π ≈ 3.14159。
    *   exp(y) 就是 $e^y$。

    这个公式看起来复杂，但它精确地定义了那个钟形曲线。
*   **Demo:** 假设某地成年男性的身高服从正态分布，均值为 175cm (μ=175)，方差为 25 (σ²=25，即标准差 $\sigma=5$cm)。

    *   身高恰好为 180cm (x=180) 的概率密度是 $f(180 | \mu=175, \sigma^2=25) = \frac{1}{\sqrt{2\pi \times 25}} \exp\left(-\frac{(180-175)^2}{2 \times 25}\right) = \frac{1}{\sqrt{50\pi}} \exp\left(-\frac{25}{50}\right) \approx \frac{1}{12.53} e^{-0.5} \approx 0.0484$。
*   **MLE 应用：** 观测到 n 个样本数据 $x_1, ..., x_n$，假设它们来自 $N(\mu, \sigma^2)$。

    *   单个观测 $x_i$ 的概率密度是 $f(x_i | \mu, \sigma^2)$ (上面的公式)。
    *   联合似然函数 $L(\mu, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i-\mu)^2}{2\sigma^2}\right)$。
    *   对数似然函数 $\ell(\mu, \sigma^2) = \sum_{i=1}^{n} \left[ \ln\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) - \frac{(x_i-\mu)^2}{2\sigma^2} \right] = \sum_{i=1}^{n} \left[ -\frac{1}{2}\ln(2\pi) - \frac{1}{2}\ln(\sigma^2) - \frac{(x_i-\mu)^2}{2\sigma^2} \right] = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (x_i - \mu)^2$
    *   分别对 μ 和 σ² 求偏导数，并令它们等于零。
    *   解得 MLE 估计值：

        *   $\hat{\mu}_{MLE} = \frac{1}{n} \sum_{i=1}^{n} x_i = \bar{x}$ （样本均值）
        *   $\hat{\sigma}^2_{MLE} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2$ （样本方差，注意分母是 n 而不是 n-1）

**总结与 MLE 连接**

你看，每种分布都有其适用的场景、需要估计的参数 θ、以及一个核心的数学表达式 P(X=k∣θ) (PMF for discrete) 或 f(x∣θ) (PDF for continuous)。

当你使用 MLE 时，构建联合似然函数的步骤是：

1.  根据你的数据特点和业务场景，选择一个合适的概率分布模型。 这是最关键的一步，需要基于对数据生成过程的理解。
2.  写出该分布的 PMF 或 PDF 表达式 P(xi∣θ) 或 f(xi∣θ)。 这是数学基础。
3.  假设你的 n 个数据点 x1,...,xn 是独立同分布 (i.i.d.) 的。 这是标准假设。
4.  将每个数据点的 PMF/PDF 值连乘起来，得到似然函数 L(θ):
    *   离散: $L(\theta) = \prod_{i=1}^{n} P(x_i | \theta)$
    *   连续: $L(\theta) = \prod_{i=1}^{n} f(x_i | \theta)$

    这就是你问的“构建联合分布函数”在 MLE 语境下的具体操作——构建似然函数。
5.  （通常）取对数得到对数似然函数 $ℓ(θ) = ∑i=1n lnP(xi∣θ)$ 或 $ℓ(θ) = ∑i=1n lnf(xi∣θ)$。
6.  通过优化方法（求导置零或数值优化）找到使 ℓ(θ) 最大的参数 $θ^MLE$。

希望这个由浅入深、结合例子的梳理能帮助你更好地理解概率分布及其在 MLE 中的应用。不用担心一次性全部记住，关键是理解核心思想和流程，需要时再查阅具体的公式。多练习几个例子会更有帮助！
